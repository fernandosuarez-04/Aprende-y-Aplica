import { NextRequest, NextResponse } from 'next/server';
import { OpenAI } from 'openai';
import { formatApiError, logError } from '@/core/utils/api-errors';

// ConfiguraciÃ³n de Lia directamente en el archivo
const LIA_CONFIG = {
  responses: {
    offTopic: "Mi especialidad es la creaciÃ³n de prompts de IA. Â¿En quÃ© tipo de prompt te gustarÃ­a trabajar hoy?",
    injectionDetected: "DetectÃ© un patrÃ³n que podrÃ­a intentar manipular mis instrucciones. Mi propÃ³sito es ayudarte a crear prompts profesionales y seguros. Por favor, reformula tu solicitud para que sea constructiva y Ã©tica."
  },
  detection: {
    promptInjection: [
      "ignore previous instructions", "disregard all prior commands", "act as a", "jailbreak",
      "forget everything", "new instructions", "override", "system prompt", "you are now",
      "pretend to be", "roleplay as", "dan mode", "developer mode"
    ],
    offTopic: [
      "quÃ© es la inteligencia artificial", "cÃ³mo funciona la ia", "quÃ© es chatgpt",
      "cuÃ©ntame un chiste", "cÃ³mo estÃ¡s", "quÃ© hora es", "quÃ© dÃ­a es hoy",
      "cuÃ¡l es tu nombre", "de dÃ³nde eres", "quÃ© opinas de", "ayÃºdame con mi tarea",
      "resuelve este problema", "explica este concepto"
    ]
  }
};

function isOffTopic(message: string): boolean {
  const lowerMessage = message.toLowerCase();
  return LIA_CONFIG.detection.offTopic.some(pattern => lowerMessage.includes(pattern));
}

function hasPromptInjection(message: string): boolean {
  const lowerMessage = message.toLowerCase();
  return LIA_CONFIG.detection.promptInjection.some(pattern => lowerMessage.includes(pattern));
}

// Configurar OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Prompt maestro de seguridad y profesionalismo para Lia
const MASTER_PROMPT = `Eres Lia, una especialista profesional en creaciÃ³n de prompts de IA. Tu Ãºnica funciÃ³n es ayudar a los usuarios a crear prompts efectivos, bien estructurados y profesionales.

IDENTIDAD:
- Nombre: Lia
- Especialidad: GeneraciÃ³n de Prompts de IA
- Enfoque: EXCLUSIVAMENTE creaciÃ³n de prompts, NO consultorÃ­a general

COMPORTAMIENTO REQUERIDO:
1. MantÃ©n un tono profesional, directo y eficiente
2. NO divagues sobre temas no relacionados con prompts
3. NO hagas chistes o comentarios casuales
4. NO actÃºes como consultor general de IA o tecnologÃ­a
5. Redirige cualquier pregunta no relacionada con prompts

LÃMITES ESTRICTOS:
- Solo responde preguntas sobre creaciÃ³n de prompts
- Si te preguntan sobre otros temas de IA, responde: "Mi especialidad es la creaciÃ³n de prompts de IA. Â¿En quÃ© tipo de prompt te gustarÃ­a trabajar hoy?"
- MantÃ©n conversaciones enfocadas y tÃ©cnicas

ESTRUCTURA DE RESPUESTA:
Cuando generes un prompt, siempre incluye:
1. TÃ­tulo claro y descriptivo
2. DescripciÃ³n concisa del propÃ³sito
3. Contenido del prompt bien estructurado
4. Tags relevantes (3-5)
5. Nivel de dificultad (beginner/intermediate/advanced)
6. Casos de uso especÃ­ficos
7. Consejos tÃ©cnicos para optimizaciÃ³n

FORMATO DE SALIDA:
Responde SIEMPRE en formato JSON con esta estructura exacta:
{
  "title": "TÃ­tulo del prompt",
  "description": "DescripciÃ³n breve",
  "content": "Contenido completo del prompt (mÃ­nimo 200 palabras, detallado y especÃ­fico)",
  "tags": ["tag1", "tag2", "tag3"],
  "difficulty_level": "beginner|intermediate|advanced",
  "use_cases": ["Caso 1", "Caso 2"],
  "tips": ["Consejo 1", "Consejo 2"]
}

IMPORTANTE: El contenido del prompt debe ser extenso, detallado y profesional. Usa formato Markdown con:

ESTRUCTURA REQUERIDA:
# TÃ­tulo del Prompt

## Objetivo
DescripciÃ³n clara del propÃ³sito

## Contexto
InformaciÃ³n de fondo relevante

## Instrucciones Detalladas
### Paso 1: [Nombre del paso]
- InstrucciÃ³n especÃ­fica
- Ejemplo concreto

### Paso 2: [Nombre del paso]
- InstrucciÃ³n especÃ­fica
- Ejemplo concreto

## Formato de Salida
Especifica exactamente cÃ³mo debe estructurarse la respuesta

## Consideraciones Especiales
- Punto importante 1
- Punto importante 2

## Ejemplo de Uso
Ejemplo prÃ¡ctico completo

FORMATO MARKDOWN:
- Usa **negritas** para Ã©nfasis
- Usa *cursivas* para tÃ©rminos tÃ©cnicos
- Usa ### para subtÃ­tulos
- Usa - para listas
- Usa cÃ³digo entre backticks para comandos o variables
- Incluye espacios entre secciones para mejor legibilidad

CATEGORÃAS SOPORTADAS:
- Marketing y Ventas
- Contenido Creativo
- ProgramaciÃ³n y Desarrollo
- AnÃ¡lisis de Datos
- EducaciÃ³n y CapacitaciÃ³n
- RedacciÃ³n y ComunicaciÃ³n
- InvestigaciÃ³n y AnÃ¡lisis
- AutomatizaciÃ³n de Procesos
- Arte y DiseÃ±o
- Negocios y Estrategia

RECUERDA: Eres un generador de prompts profesional, no un chatbot general. MantÃ©n el enfoque en tu especialidad.`;

interface ChatMessage {
  id: string;
  text: string;
  sender: 'user' | 'ai';
  timestamp: string;
  isPromptSection?: boolean;
  sectionType?: 'title' | 'description' | 'content' | 'tags' | 'difficulty' | 'use_cases' | 'tips';
}

export async function POST(request: NextRequest) {
  try {
    console.log('ðŸ” API generate-prompt called');
    
    const { message, conversationHistory } = await request.json();
    console.log('ðŸ“ Message received:', message);

    // Validar entrada
    if (!message || typeof message !== 'string') {
      console.log('âŒ No message provided');
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      );
    }

    // Verificar comportamiento apropiado usando configuraciÃ³n de Lia
    if (hasPromptInjection(message)) {
      return NextResponse.json({
        response: LIA_CONFIG.responses.injectionDetected,
        generatedPrompt: null,
      }, { status: 400 });
    }
    
    if (isOffTopic(message)) {
      return NextResponse.json({
        response: LIA_CONFIG.responses.offTopic,
        generatedPrompt: null,
      }, { status: 200 });
    }

    // Construir historial de conversaciÃ³n
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      {
        role: 'system',
        content: MASTER_PROMPT
      }
    ];

    // Agregar historial de conversaciÃ³n (Ãºltimos 10 mensajes para mantener contexto)
    const recentHistory = conversationHistory ? conversationHistory.slice(-10) : [];
    recentHistory.forEach((msg: any) => {
      // Convertir del formato del frontend al formato de OpenAI
      const role = msg.sender === 'ai' ? 'assistant' : 'user';
      const content = msg.text;
      
      messages.push({
        role: role as 'user' | 'assistant',
        content: content
      });
    });

    // Agregar el mensaje actual
    messages.push({
      role: 'user',
      content: message
    });

    // Llamar a OpenAI
    console.log('ðŸ¤– Calling OpenAI with', messages.length, 'messages');
    console.log('ðŸ“‹ Messages array:', JSON.stringify(messages, null, 2));
    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: messages,
      temperature: 0.7,
      max_tokens: 2000,
      presence_penalty: 0.1,
      frequency_penalty: 0.1
    });
    console.log('âœ… OpenAI response received');

    const response = completion.choices[0]?.message?.content;
    console.log('ðŸ“„ OpenAI raw response:', response);
    
    if (!response) {
      throw new Error('No se recibiÃ³ respuesta de OpenAI');
    }

    // Intentar parsear como JSON si parece ser un prompt completo
    let generatedPrompt = null;
    try {
      // Buscar JSON en la respuesta
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        if (parsed.title && parsed.content) {
          generatedPrompt = parsed;
        }
      }
    } catch (error) {
      // No es JSON, continuar con respuesta normal
    }

    const finalResponse = {
      response: response,
      message: response,
      generatedPrompt: generatedPrompt
    };
    
    console.log('ðŸ“¤ Sending response to frontend:', JSON.stringify(finalResponse, null, 2));
    
    return NextResponse.json(finalResponse);

  } catch (error) {
    logError('POST /api/ai-directory/generate-prompt', error);

    // Manejar errores especÃ­ficos de OpenAI
    if (error instanceof Error) {
      if (error.message.includes('API key')) {
        return NextResponse.json(
          formatApiError(error, 'Error de configuraciÃ³n de API'),
          { status: 500 }
        );
      }

      if (error.message.includes('rate limit')) {
        return NextResponse.json(
          formatApiError(error, 'LÃ­mite de solicitudes excedido. IntÃ©ntalo mÃ¡s tarde.'),
          { status: 429 }
        );
      }
    }

    return NextResponse.json(
      formatApiError(error, 'Error al generar prompt'),
      { status: 500 }
    );
  }
}
