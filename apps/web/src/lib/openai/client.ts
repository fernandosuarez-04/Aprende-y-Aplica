/**
 * ü§ñ OpenAI Client Configuration
 *
 * Cliente centralizado de OpenAI con:
 * - Configuraci√≥n singleton
 * - Integraci√≥n con sistema de monitoreo de uso
 * - Rate limiting
 * - Error handling
 */

import OpenAI from 'openai';
import { logOpenAIUsage, calculateCost, checkUsageLimit } from './usage-monitor';

// Singleton instance
let openaiClient: OpenAI | null = null;

/**
 * Obtiene o crea la instancia del cliente de OpenAI
 */
export function getOpenAIClient(): OpenAI {
  if (openaiClient) {
    return openaiClient;
  }

  // üîç Debug: Verificar variables de entorno
  console.log('üîç [DEBUG] Variables de entorno:', {
    OPENAI_API_KEY: process.env.OPENAI_API_KEY ? 'Configurada' : 'No configurada',
    NEXT_PUBLIC_OPENAI_API_KEY: process.env.NEXT_PUBLIC_OPENAI_API_KEY ? 'Configurada' : 'No configurada',
    has_OPENAI: !!process.env.OPENAI_API_KEY,
    has_NEXT_PUBLIC: !!process.env.NEXT_PUBLIC_OPENAI_API_KEY
  });

  const apiKey = process.env.OPENAI_API_KEY || process.env.NEXT_PUBLIC_OPENAI_API_KEY;

  if (!apiKey) {
    console.error('‚ùå [ERROR] No se encontr√≥ ninguna API key de OpenAI');
    console.error('process.env:', Object.keys(process.env).filter(k => k.includes('OPENAI')));
    throw new Error(
      'OPENAI_API_KEY no est√° configurada. ' +
      'Por favor, agrega OPENAI_API_KEY a tu archivo .env.local'
    );
  }

  openaiClient = new OpenAI({
    apiKey,
    dangerouslyAllowBrowser: true // Solo para desarrollo, en producci√≥n usar API routes
  });

  console.log('‚úÖ [OPENAI] Cliente inicializado correctamente');

  return openaiClient;
}

/**
 * Wrapper para chat completions con monitoreo integrado
 */
export async function createChatCompletion(
  params: {
    model?: string;
    messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>;
    temperature?: number;
    max_tokens?: number;
    response_format?: { type: 'json_object' | 'text' };
  },
  userId: string = 'anonymous'
): Promise<OpenAI.Chat.Completions.ChatCompletion> {
  const client = getOpenAIClient();

  // Verificar l√≠mites de uso
  const usageCheck = checkUsageLimit(userId);
  if (!usageCheck.allowed) {
    throw new Error(usageCheck.reason || 'L√≠mite de uso excedido');
  }

  try {
    const response = await client.chat.completions.create({
      model: params.model || 'gpt-4o-mini',
      messages: params.messages,
      temperature: params.temperature ?? 0.7,
      max_tokens: params.max_tokens ?? 1000,
      response_format: params.response_format
    });

    // Registrar uso
    const usage = response.usage;
    if (usage) {
      const cost = calculateCost(
        usage.prompt_tokens,
        usage.completion_tokens,
        params.model || 'gpt-4o-mini'
      );

      logOpenAIUsage({
        userId,
        timestamp: new Date(),
        model: params.model || 'gpt-4o-mini',
        promptTokens: usage.prompt_tokens,
        completionTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        estimatedCost: cost
      });

      console.log('üí∞ [OPENAI] Uso registrado:', {
        model: params.model || 'gpt-4o-mini',
        tokens: usage.total_tokens,
        cost: `$${cost.toFixed(4)}`
      });
    }

    return response;

  } catch (error: any) {
    console.error('‚ùå [OPENAI] Error en la llamada:', error);

    // Manejar errores espec√≠ficos de OpenAI
    if (error.status === 429) {
      throw new Error('Rate limit excedido. Por favor, intenta de nuevo en unos momentos.');
    } else if (error.status === 401) {
      throw new Error('API key inv√°lida. Por favor, verifica tu configuraci√≥n.');
    } else if (error.status === 500) {
      throw new Error('Error en el servidor de OpenAI. Por favor, intenta de nuevo.');
    }

    throw error;
  }
}

/**
 * Resetea el cliente (√∫til para testing)
 */
export function resetOpenAIClient(): void {
  openaiClient = null;
  console.log('üîÑ [OPENAI] Cliente reseteado');
}
