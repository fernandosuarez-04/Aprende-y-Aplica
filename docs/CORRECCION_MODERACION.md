# ğŸš¨ CORRECCIÃ“N DE MODERACIÃ“N - MEJORAS CRÃTICAS

## âŒ Problema Detectado

Tu publicaciÃ³n NO fue bloqueada:
```
"prueba de moderador de malas palabras: mu3rt3 1d10t4s, que csm morena, 
voy a explotar las torres gemelas. arriba las dr0gas y abajo el perreo"
```

**Resultados del anÃ¡lisis:**
- âœ… OpenAI Moderation detectÃ³: `violence` con 51.1% confianza
- âŒ No se bloqueÃ³ porque el umbral era 70%
- âŒ Palabras con leetspeak no fueron detectadas (mu3rt3, 1d10t4s, dr0gas)
- âŒ Amenazas terroristas no fueron bloqueadas

## âœ… Soluciones Implementadas

### 1. **Nuevas Palabras Prohibidas con Leetspeak**
Se agregaron 50+ variantes con nÃºmeros:
- `mu3rt3`, `m4t4r`, `as3sin0` â†’ muerte, matar, asesino
- `1d10t4`, `1di0t4`, `id10ta` â†’ idiota
- `dr0g4s`, `dr0gas`, `c0ca1na` â†’ drogas, cocaÃ­na
- `csm`, `ctm`, `hdp` â†’ insultos abreviados
- `explota`, `explotar`, `bomba`, `terrorista`, `torres gemelas` â†’ amenazas

### 2. **Umbrales de Confianza Ajustados**
**ANTES:**
- Umbral de bloqueo: 70%
- Umbral de baneo: 95%

**AHORA:**
- Umbral de bloqueo: **50%** â¬‡ï¸ (mÃ¡s sensible)
- Umbral de baneo: **85%** â¬‡ï¸ (mÃ¡s estricto)

### 3. **AnÃ¡lisis Contextual con GPT**
Si OpenAI Moderation detecta algo pero con confianza <70%, ahora:
- âœ… Se ejecuta anÃ¡lisis adicional con GPT-4o-mini
- âœ… GPT analiza el contexto y detecta leetspeak
- âœ… Si GPT confirma, se usa su confianza (mÃ¡s alta)

### 4. **Prompt de GPT Mejorado**
El prompt ahora es **ESTRICTO** y detecta:
- Amenazas terroristas â†’ confianza 95%+
- Leetspeak (mu3rt3, dr0gas, etc.)
- Referencias a drogas
- Insultos con abreviaturas (csm, hdp)

## ğŸ“‹ PASOS PARA APLICAR

### Paso 1: Ejecutar SQL (Agregar Palabras Prohibidas)

```sql
-- En Supabase SQL Editor, ejecuta:
```

Copia y ejecuta todo el contenido de:
`database-fixes/moderacion-palabras-variantes.sql`

### Paso 2: Reiniciar el Servidor

El archivo `.env.local` ya fue actualizado con los nuevos umbrales.

```bash
# DetÃ©n el servidor (Ctrl+C)
# Reinicia:
npm run dev
```

### Paso 3: Probar Nuevamente

Publica esta misma frase:
```
prueba de moderador de malas palabras: mu3rt3 1d10t4s, que csm morena, 
voy a explotar las torres gemelas. arriba las dr0gas y abajo el perreo
```

**Resultado esperado:**
```
âœ… Post created successfully: [id]
ğŸ¤– Starting AI moderation analysis...
âš ï¸ Low confidence detection, running GPT contextual analysis...
ğŸ¯ GPT confirmed inappropriate content: 95.0%
ğŸš¨ Inappropriate content detected! Deleting post: [id]
âœ… Post deleted successfully
âš ï¸ Warning registered for user
```

## ğŸ” VerificaciÃ³n en Consola

DeberÃ­as ver estos logs:

1. **OpenAI Moderation:**
```
ğŸ¤– AI Moderation Result: {
  isInappropriate: false,
  confidence: '51.1%',
  categories: ['violence']
}
```

2. **GPT Analysis (nuevo):**
```
âš ï¸ Low confidence detection, running GPT contextual analysis...
ğŸ¯ GPT confirmed inappropriate content: {
  gptConfidence: '95.0%',
  openAIConfidence: '51.1%',
  categories: ['violence', 'threats', 'drugs']
}
```

3. **EliminaciÃ³n:**
```
ğŸš¨ Inappropriate content detected! Deleting post: [id]
âœ… Post deleted successfully
âš ï¸ Warning registered for user
```

## ğŸ“Š Palabras Prohibidas Agregadas

### Violencia (Critical/High)
- mu3rt3, mu3rte, m4t4r, mat4r, as3sin0, asesino
- explota, explotar, bomba, terrorista, atentado, torres gemelas

### Drogas (High)
- dr0g4s, dr0gas, drog4s, c0ca1na, cocaina, m4rihu4na, marihuana

### Insultos (High/Medium)
- 1d10t4, 1di0t4, id10ta, idi0ta
- 3stup1d0, estup1do
- csm, ctm, ptm, hdp, hpt
- put4, p3rr4, z0rra, zorra
- verga, v3rg4, chingada, pendejo, p3nd3j0
- cabron, c4bron, marica, m4ric4
- mi3rd4, mierda, mierd4

### Total: 50+ palabras nuevas

## ğŸ¯ Comportamiento Esperado

### Contenido con Leetspeak
```
Entrada: "eres un 1d10t4 de mi3rd4"
Resultado: âŒ BLOQUEADO por Capa 1 (palabra prohibida: 1d10t4, mi3rd4)
```

### Amenazas Veladas
```
Entrada: "voy a explotar el lugar"
Resultado: âŒ BLOQUEADO por Capa 1 (palabra crÃ­tica: explotar)
```

### Contexto Inapropiado (sin palabras prohibidas exactas)
```
Entrada: "deberÃ­as desaparecer permanentemente"
Resultado: 
- âœ… Pasa Capa 1 (no hay palabras prohibidas)
- ğŸ¤– OpenAI detecta: violence 45%
- ğŸ¯ GPT analiza contexto: 75% inapropiado
- âŒ POST SE ELIMINA
```

## âš ï¸ Notas Importantes

1. **Los umbrales mÃ¡s bajos** significan que el sistema serÃ¡ mÃ¡s sensible
2. **GPT Analysis cuesta mÃ¡s** pero solo se ejecuta cuando OpenAI detecta algo
3. **Las palabras con nÃºmeros** ahora se detectan igual que las normales
4. **Amenazas terroristas** tienen severidad CRITICAL y deben resultar en baneo

## ğŸ”§ Troubleshooting

### Si sigue sin funcionar:

1. **Verifica la consola del servidor:**
   ```
   âš ï¸ Low confidence detection, running GPT contextual analysis...
   ```
   Si no ves esto, el anÃ¡lisis GPT no se estÃ¡ ejecutando.

2. **Verifica las variables de entorno:**
   ```bash
   AI_MODERATION_CONFIDENCE_THRESHOLD=0.50
   AI_MODERATION_AUTO_BAN_THRESHOLD=0.85
   ```

3. **Verifica que las palabras prohibidas se agregaron:**
   ```sql
   SELECT COUNT(*) FROM forbidden_words;
   -- DeberÃ­as ver 70+ palabras
   ```

4. **Revisa los logs de OpenAI:**
   - Si ves errores de API key, verifica `OPENAI_API_KEY`
   - Si ves errores de rate limit, espera unos minutos

## ğŸ“ˆ PrÃ³ximos Pasos

DespuÃ©s de probar:
1. âœ… Confirma que el post se elimina
2. âœ… Confirma que recibes advertencia
3. âœ… Prueba 4 veces para verificar el baneo automÃ¡tico
4. âœ… Revisa el panel de admin en `/admin/moderation-ai`
